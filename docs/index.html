
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"
   "http://www.w3.org/TR/html4/strict.dtd">

<html>
<head>
  <title></title>
  <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  <style type="text/css">
body {
    background: #000000;
    color: #FFFFFF;
}
h1 {
    color: #EEEEEE;
    background: #111111;
    margin: 0px;
    text-align: center;
    padding: 10px;
}
div.buttons {
    width: 100%;
    display: flex;
    justify-content: center;
}
div.main {
    display: flex;
    flex-direction: column;
    align-items: center;     /* center items horizontally, in this case */
    padding-top: 10px;
}
div.header-outer {
    display: flex;
    flex-direction: column;
    align-items: center;
    background: #111111;
    color: #EEEEEE;
    margin: 0px;
    padding: 10px;
    font-size: large;
}
div.disqus {
    max-width: 1000px;
    margin: auto;
}
div.header {
    max-width: 1000px;
}
div.outer {
    clear: both;
}
div.description {
    font-size: large;
    color: #36e6e8;
    text-align: justify;
    line-height: 112%;
    width: 400px;
    float: left;
}
code  {
    background: #000000;
    color: #FFFFFF;
    float: right;
    width: 100ch;
    padding-left: 15px;
}
code.empty {
    background: #666666;
    margin-top: 8px;
    max-height: 3px;
}
code.dynet {
}
code.pytorch {
}
code.tensorflow {
}
a {
    color: #00a1d6;
}
.button {
    cursor: pointer;
    background-color: #008CBA;
    border: 10px;
    margin: 5px;
    color: white;
    padding: 15px 32px;
    text-align: center;
    text-decoration: none;
    display: inline-block;
    font-size: 16px;
}
td.linenos { background-color: #f0f0f0; padding-right: 10px; }
span.lineno { background-color: #f0f0f0; padding: 0 5px 0 5px; }
pre { line-height: 125%; font-family: Menlo, "Courier New", Courier, monospace; margin: 0 }
body .hll { background-color: #ffffcc }
body .c { color: #408080; } /* Comment */
body .err { border: 1px solid #FF0000 } /* Error */
body .k { color: #fceb60; } /* Keyword */
body .o { color: #FFFFFF } /* Operator */
body .ch { color: #36e6e8; } /* Comment.Hashbang */
body .cm { color: #36e6e8; } /* Comment.Multiline */
body .cp { color: #36e6e8 } /* Comment.Preproc */
body .cpf { color: #36e6e8; } /* Comment.PreprocFile */
body .c1 { color: #36e6e8; } /* Comment.Single */
body .cs { color: #36e6e8; } /* Comment.Special */
body .gd { color: #A00000 } /* Generic.Deleted */
body .ge { font-style: italic } /* Generic.Emph */
body .gr { color: #FF0000 } /* Generic.Error */
body .gh { color: #000080; } /* Generic.Heading */
body .gi { color: #00A000 } /* Generic.Inserted */
body .go { color: #888888 } /* Generic.Output */
body .gp { color: #000080; } /* Generic.Prompt */
body .gs { font-weight: bold } /* Generic.Strong */
body .gu { color: #800080; } /* Generic.Subheading */
body .gt { color: #0044DD } /* Generic.Traceback */
body .kc { color: #008000; } /* Keyword.Constant */
body .kd { color: #008000; } /* Keyword.Declaration */
body .kn { color: #84b0d9; } /* Keyword.Namespace */
body .kp { color: #008000 } /* Keyword.Pseudo */
body .kr { color: #008000; } /* Keyword.Reserved */
body .kt { color: #B00040 } /* Keyword.Type */
body .m { color: #BC94B7 } /* Literal.Number */
body .s { color: #BC94B7 } /* Literal.String */
body .na { color: #7D9029 } /* Name.Attribute */
body .nb { color: #36e6e8 } /* Name.Builtin */
body .nc { color: #36e6e8; } /* Name.Class */
body .no { color: #880000 } /* Name.Constant */
body .nd { color: #AA22FF } /* Name.Decorator */
body .ni { color: #999999; } /* Name.Entity */
body .ne { color: #D2413A; } /* Name.Exception */
body .nf { color: #36e6e8 } /* Name.Function */
body .nl { color: #A0A000 } /* Name.Label */
body .nn { color: #FFFFFF; } /* Name.Namespace */
body .nt { color: #008000; } /* Name.Tag */
body .nv { color: #19177C } /* Name.Variable */
body .ow { color: #fceb60; } /* Operator.Word */
body .w { color: #bbbbbb } /* Text.Whitespace */
body .mb { color: #BC94B7 } /* Literal.Number.Bin */
body .mf { color: #BC94B7 } /* Literal.Number.Float */
body .mh { color: #BC94B7 } /* Literal.Number.Hex */
body .mi { color: #BC94B7 } /* Literal.Number.Integer */
body .mo { color: #BC94B7 } /* Literal.Number.Oct */
body .sa { color: #BC94B7 } /* Literal.String.Affix */
body .sb { color: #BC94B7 } /* Literal.String.Backtick */
body .sc { color: #BC94B7 } /* Literal.String.Char */
body .dl { color: #BC94B7 } /* Literal.String.Delimiter */
body .sd { color: #BC94B7; } /* Literal.String.Doc */
body .s2 { color: #BC94B7 } /* Literal.String.Double */
body .se { color: #BB6622; } /* Literal.String.Escape */
body .sh { color: #BC94B7 } /* Literal.String.Heredoc */
body .si { color: #BB6688; } /* Literal.String.Interpol */
body .sx { color: #008000 } /* Literal.String.Other */
body .sr { color: #BB6688 } /* Literal.String.Regex */
body .s1 { color: #BC94B7 } /* Literal.String.Single */
body .ss { color: #19177C } /* Literal.String.Symbol */
body .bp { color: #36e6e8 } /* Name.Builtin.Pseudo */
body .fm { color: #36e6e8 } /* Name.Function.Magic */
body .vc { color: #FFFFFF } /* Name.Variable.Class */
body .vg { color: #FFFFFF } /* Name.Variable.Global */
body .vi { color: #FFFFFF } /* Name.Variable.Instance */
body .vm { color: #FFFFFF } /* Name.Variable.Magic */
body .il { color: #BC94B7 } /* Literal.Number.Integer.Long */
</style>
</head>

<body onload="toggleDyNet(); togglePyTorch(); toggleTensorflow()">

<h1>Implementing a neural Part-of-Speech tagger</h1>
<div class="header-outer">
<div class=header>
<p>
DyNet, PyTorch and Tensorflow are complex frameworks with different ways of approaching neural network implementation and different default behaviour.
This page is intended to show how to implement a non-trivial model in all three.
The design of the page is motivated by my own preference for an annotated complete piece of code, rather than introducing parts piecemeal with discussion.
For a non-tutorial version it would be better to use abstraction to improve flexibility, but that would have complicated the flow here.
</p>
<p>
Use the buttons to show one or more implementations and their associated comments.
Shared content is repeated and aligned.
Implementation-specific content is shown with empty space for the other implementations and lines to make the link from a comment to the code clear.
The <a href="https://github.com/jkkummerfeld/neural-tagger-tutorial">repository</a> for this page provides the code in runnable form.
The only dependencies are the respective frameworks (DyNet <a href="https://github.com/clab/dynet/releases/tag/2.0.3">2.0.3</a>, PyTorch <a href="https://github.com/pytorch/pytorch/releases/tag/v0.4.1">0.4.1</a> and Tensorflow <a href="https://github.com/tensorflow/tensorflow/releases/tag/v1.9.0">1.9.0</a>).
</p>
<p>
The three implementations below all produce part-of-speech taggers that score ~97.2% on the development set of the Penn Treebank.
The specific hyperparameter choices follows <a href="https://arxiv.org/abs/1806.04470">Yang, Liang, and Zhang (CoLing 2018)</a> and matches their performance for the setting without a CRF layer or character-based word embeddings.
</p>
<p>
Making this helped me understand all three frameworks better. Hopefully you find it informative too!
</p>

<div class="buttons">
<button class="button" id="dybutton" onmouseover="" onclick="toggleDyNet()">Hide DyNet</button>
<button class="button" id="ptbutton" onmouseover="" onclick="togglePyTorch()">Hide PyTorch</button>
<button class="button" id="tfbutton" onmouseover="" onclick="toggleTensorflow()">Hide Tensorflow</button>
</div>
</div>

</div>


<div class="main">
<div class="outer  shared-content">
<div class="description shared-content">Imports<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span><span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

</pre></div></code>
<code class="pytorch">
<div class="source"><pre><span></span><span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

</pre></div></code>
<code class="dynet">
<div class="source"><pre><span></span><span class="kn">import</span> <span class="nn">argparse</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

</pre></div></code>
</div>
<div class="outer  shared-content">
<div class="description shared-content">Constants
<br />
Typically, we would make many of these command line arguments and tune using the development set. For simplicity, I have fixed their values here to match Jiang, Liang and Zhang (CoLing 2018).<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span><span class="n">PAD</span> <span class="o">=</span> <span class="s2">&quot;__PAD__&quot;</span>
<span class="n">UNK</span> <span class="o">=</span> <span class="s2">&quot;__UNK__&quot;</span>
<span class="n">DIM_EMBEDDING</span> <span class="o">=</span> <span class="mi">100</span> 
<span class="n">LSTM_HIDDEN</span> <span class="o">=</span> <span class="mi">100</span> 
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">10</span> 
<span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="mf">0.015</span> 
<span class="n">LEARNING_DECAY_RATE</span> <span class="o">=</span> <span class="mf">0.05</span> 
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">100</span> 
<span class="n">KEEP_PROB</span> <span class="o">=</span> <span class="mf">0.5</span> 
<span class="n">GLOVE</span> <span class="o">=</span> <span class="s2">&quot;../data/glove.6B.100d.txt&quot;</span> 
<span class="c1"># WEIGHT_DECAY = 1e-8 See note</span>

</pre></div></code>
<code class="pytorch">
<div class="source"><pre><span></span><span class="n">PAD</span> <span class="o">=</span> <span class="s2">&quot;__PAD__&quot;</span>
<span class="n">UNK</span> <span class="o">=</span> <span class="s2">&quot;__UNK__&quot;</span>
<span class="n">DIM_EMBEDDING</span> <span class="o">=</span> <span class="mi">100</span> 
<span class="n">LSTM_HIDDEN</span> <span class="o">=</span> <span class="mi">100</span> 
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">10</span> 
<span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="mf">0.015</span> 
<span class="n">LEARNING_DECAY_RATE</span> <span class="o">=</span> <span class="mf">0.05</span> 
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">100</span> 
<span class="n">KEEP_PROB</span> <span class="o">=</span> <span class="mf">0.5</span> 
<span class="n">GLOVE</span> <span class="o">=</span> <span class="s2">&quot;../data/glove.6B.100d.txt&quot;</span> 
<span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">1e-8</span>

</pre></div></code>
<code class="dynet">
<div class="source"><pre><span></span><span class="n">PAD</span> <span class="o">=</span> <span class="s2">&quot;__PAD__&quot;</span>
<span class="n">UNK</span> <span class="o">=</span> <span class="s2">&quot;__UNK__&quot;</span>
<span class="n">DIM_EMBEDDING</span> <span class="o">=</span> <span class="mi">100</span> 
<span class="n">LSTM_HIDDEN</span> <span class="o">=</span> <span class="mi">100</span> 
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">10</span> 
<span class="n">LEARNING_RATE</span> <span class="o">=</span> <span class="mf">0.015</span> 
<span class="n">LEARNING_DECAY_RATE</span> <span class="o">=</span> <span class="mf">0.05</span> 
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">100</span> 
<span class="n">KEEP_PROB</span> <span class="o">=</span> <span class="mf">0.5</span> 
<span class="n">GLOVE</span> <span class="o">=</span> <span class="s2">&quot;../data/glove.6B.100d.txt&quot;</span> 
<span class="n">WEIGHT_DECAY</span> <span class="o">=</span> <span class="mf">1e-8</span>

</pre></div></code>
</div>
<div class="outer  dynet">
<div class="description dynet">DyNet specfic imports
<br />
The first allows us to configure DyNet from within code rather than on the command line:  mem is the amount of system memory initially allocated (DyNet has its own memory management), autobatch toggles automatic parallelisation of computations, weight_decay rescales weights by (1 - decay) after every update, random_seed sets the seed for random number generation.<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
&nbsp;</code>
<code class="dynet">
<div class="source"><pre><span></span><span class="kn">import</span> <span class="nn">dynet_config</span>
<span class="n">dynet_config</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">mem</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">autobatch</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">,</span><span class="n">random_seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># dynet_config.set_gpu() </span>
<span class="kn">import</span> <span class="nn">dynet</span> <span class="kn">as</span> <span class="nn">dy</span>

</pre></div></code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">PyTorch specfic imports<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

</pre></div></code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">Tensorflow specfic import<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>

</pre></div></code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  shared-content">
<div class="description shared-content">Reading the data<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span><span class="k">def</span> <span class="nf">read_data</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Example input:</span>
<span class="sd">    Pierre|NNP Vinken|NNP ,|, 61|CD years|NNS old|JJ</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">content</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span> <span class="k">as</span> <span class="n">data_src</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">data_src</span><span class="p">:</span>
            <span class="n">t_p</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;|&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">t_p</span><span class="p">]</span>
            <span class="n">tags</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">t_p</span><span class="p">]</span>
            <span class="n">content</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">tokens</span><span class="p">,</span> <span class="n">tags</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">content</span>

</pre></div></code>
<code class="pytorch">
<div class="source"><pre><span></span><span class="k">def</span> <span class="nf">read_data</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Example input:</span>
<span class="sd">    Pierre|NNP Vinken|NNP ,|, 61|CD years|NNS old|JJ</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">content</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span> <span class="k">as</span> <span class="n">data_src</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">data_src</span><span class="p">:</span>
            <span class="n">t_p</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;|&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">t_p</span><span class="p">]</span>
            <span class="n">tags</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">t_p</span><span class="p">]</span>
            <span class="n">content</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">tokens</span><span class="p">,</span> <span class="n">tags</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">content</span>

</pre></div></code>
<code class="dynet">
<div class="source"><pre><span></span><span class="k">def</span> <span class="nf">read_data</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Example input:</span>
<span class="sd">    Pierre|NNP Vinken|NNP ,|, 61|CD years|NNS old|JJ</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">content</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span> <span class="k">as</span> <span class="n">data_src</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">data_src</span><span class="p">:</span>
            <span class="n">t_p</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;|&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
            <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">t_p</span><span class="p">]</span>
            <span class="n">tags</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">t_p</span><span class="p">]</span>
            <span class="n">content</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">tokens</span><span class="p">,</span> <span class="n">tags</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">content</span>

</pre></div></code>
</div>
<div class="outer  shared-content">
<div class="description shared-content">Replace all digits with 0 to decrease sparsity.<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span><span class="k">def</span> <span class="nf">simplify_token</span><span class="p">(</span><span class="n">token</span><span class="p">):</span>
    <span class="n">chars</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">token</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">char</span><span class="o">.</span><span class="n">isdigit</span><span class="p">():</span>
            <span class="n">chars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;0&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">chars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">char</span><span class="p">)</span>
    <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
</pre></div>
</code>
<code class="pytorch">
<div class="source"><pre><span></span><span class="k">def</span> <span class="nf">simplify_token</span><span class="p">(</span><span class="n">token</span><span class="p">):</span>
    <span class="n">chars</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">token</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">char</span><span class="o">.</span><span class="n">isdigit</span><span class="p">():</span>
            <span class="n">chars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;0&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">chars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">char</span><span class="p">)</span>
    <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
</pre></div>
</code>
<code class="dynet">
<div class="source"><pre><span></span><span class="k">def</span> <span class="nf">simplify_token</span><span class="p">(</span><span class="n">token</span><span class="p">):</span>
    <span class="n">chars</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">token</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">char</span><span class="o">.</span><span class="n">isdigit</span><span class="p">():</span>
            <span class="n">chars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;0&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">chars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">char</span><span class="p">)</span>
    <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">chars</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
</pre></div>
</code>
</div>
<div class="outer  shared-content">
<div class="description shared-content">Read arguments<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s1">&#39;POS tagger.&#39;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;training_data&#39;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;dev_data&#39;</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

</pre></div></code>
<code class="pytorch">
<div class="source"><pre><span></span>    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s1">&#39;POS tagger.&#39;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;training_data&#39;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;dev_data&#39;</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

</pre></div></code>
<code class="dynet">
<div class="source"><pre><span></span>    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s1">&#39;POS tagger.&#39;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;training_data&#39;</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s1">&#39;dev_data&#39;</span><span class="p">)</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

</pre></div></code>
</div>
<div class="outer  shared-content">
<div class="description shared-content">Read data (see function above)<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>    <span class="n">train</span> <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">training_data</span><span class="p">)</span>
    <span class="n">dev</span> <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">dev_data</span><span class="p">)</span>

</pre></div></code>
<code class="pytorch">
<div class="source"><pre><span></span>    <span class="n">train</span> <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">training_data</span><span class="p">)</span>
    <span class="n">dev</span> <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">dev_data</span><span class="p">)</span>

</pre></div></code>
<code class="dynet">
<div class="source"><pre><span></span>    <span class="n">train</span> <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">training_data</span><span class="p">)</span>
    <span class="n">dev</span> <span class="o">=</span> <span class="n">read_data</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">dev_data</span><span class="p">)</span>

</pre></div></code>
</div>
<div class="outer  shared-content">
<div class="description shared-content">Make indices<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>    <span class="n">id_to_token</span> <span class="o">=</span> <span class="p">[</span><span class="n">PAD</span><span class="p">,</span> <span class="n">UNK</span><span class="p">]</span>
    <span class="n">token_to_id</span> <span class="o">=</span> <span class="p">{</span><span class="n">PAD</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="n">UNK</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
    <span class="n">id_to_tag</span> <span class="o">=</span> <span class="p">[</span><span class="n">PAD</span><span class="p">]</span>
    <span class="n">tag_to_id</span> <span class="o">=</span> <span class="p">{</span><span class="n">PAD</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
</pre></div>
</code>
<code class="pytorch">
<div class="source"><pre><span></span>    <span class="n">id_to_token</span> <span class="o">=</span> <span class="p">[</span><span class="n">PAD</span><span class="p">,</span> <span class="n">UNK</span><span class="p">]</span>
    <span class="n">token_to_id</span> <span class="o">=</span> <span class="p">{</span><span class="n">PAD</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="n">UNK</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
    <span class="n">id_to_tag</span> <span class="o">=</span> <span class="p">[</span><span class="n">PAD</span><span class="p">]</span>
    <span class="n">tag_to_id</span> <span class="o">=</span> <span class="p">{</span><span class="n">PAD</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
</pre></div>
</code>
<code class="dynet">
<div class="source"><pre><span></span>    <span class="n">id_to_token</span> <span class="o">=</span> <span class="p">[</span><span class="n">PAD</span><span class="p">,</span> <span class="n">UNK</span><span class="p">]</span>
    <span class="n">token_to_id</span> <span class="o">=</span> <span class="p">{</span><span class="n">PAD</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="n">UNK</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
    <span class="n">id_to_tag</span> <span class="o">=</span> <span class="p">[</span><span class="n">PAD</span><span class="p">]</span>
    <span class="n">tag_to_id</span> <span class="o">=</span> <span class="p">{</span><span class="n">PAD</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
</pre></div>
</code>
</div>
<div class="outer  shared-content">
<div class="description shared-content">dev is necessary here to get the GloVe embeddings for words in dev but not train loaded. They will not be updated during training as they do not occur.<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>    <span class="k">for</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">tags</span> <span class="ow">in</span> <span class="n">train</span> <span class="o">+</span> <span class="n">dev</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
            <span class="n">token</span> <span class="o">=</span> <span class="n">simplify_token</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">token_to_id</span><span class="p">:</span>
                <span class="n">token_to_id</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_to_id</span><span class="p">)</span>
                <span class="n">id_to_token</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">tags</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">tag</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">tag_to_id</span><span class="p">:</span>
                <span class="n">tag_to_id</span><span class="p">[</span><span class="n">tag</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tag_to_id</span><span class="p">)</span>
                <span class="n">id_to_tag</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tag</span><span class="p">)</span>
    <span class="n">NWORDS</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_to_id</span><span class="p">)</span>
    <span class="n">NTAGS</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tag_to_id</span><span class="p">)</span>

</pre></div></code>
<code class="pytorch">
<div class="source"><pre><span></span>    <span class="k">for</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">tags</span> <span class="ow">in</span> <span class="n">train</span> <span class="o">+</span> <span class="n">dev</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
            <span class="n">token</span> <span class="o">=</span> <span class="n">simplify_token</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">token_to_id</span><span class="p">:</span>
                <span class="n">token_to_id</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_to_id</span><span class="p">)</span>
                <span class="n">id_to_token</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">tags</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">tag</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">tag_to_id</span><span class="p">:</span>
                <span class="n">tag_to_id</span><span class="p">[</span><span class="n">tag</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tag_to_id</span><span class="p">)</span>
                <span class="n">id_to_tag</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tag</span><span class="p">)</span>
    <span class="n">NWORDS</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_to_id</span><span class="p">)</span>
    <span class="n">NTAGS</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tag_to_id</span><span class="p">)</span>

</pre></div></code>
<code class="dynet">
<div class="source"><pre><span></span>    <span class="k">for</span> <span class="n">tokens</span><span class="p">,</span> <span class="n">tags</span> <span class="ow">in</span> <span class="n">train</span> <span class="o">+</span> <span class="n">dev</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
            <span class="n">token</span> <span class="o">=</span> <span class="n">simplify_token</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">token_to_id</span><span class="p">:</span>
                <span class="n">token_to_id</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_to_id</span><span class="p">)</span>
                <span class="n">id_to_token</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">tags</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">tag</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">tag_to_id</span><span class="p">:</span>
                <span class="n">tag_to_id</span><span class="p">[</span><span class="n">tag</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tag_to_id</span><span class="p">)</span>
                <span class="n">id_to_tag</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tag</span><span class="p">)</span>
    <span class="n">NWORDS</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">token_to_id</span><span class="p">)</span>
    <span class="n">NTAGS</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tag_to_id</span><span class="p">)</span>

</pre></div></code>
</div>
<div class="outer  shared-content">
<div class="description shared-content">Load pre-trained vectors<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>    <span class="n">pretrained</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="n">GLOVE</span><span class="p">):</span>
        <span class="n">parts</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
        <span class="n">word</span> <span class="o">=</span> <span class="n">parts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">vector</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">parts</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
        <span class="n">pretrained</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">vector</span>
</pre></div>
</code>
<code class="pytorch">
<div class="source"><pre><span></span>    <span class="n">pretrained</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="n">GLOVE</span><span class="p">):</span>
        <span class="n">parts</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
        <span class="n">word</span> <span class="o">=</span> <span class="n">parts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">vector</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">parts</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
        <span class="n">pretrained</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">vector</span>
</pre></div>
</code>
<code class="dynet">
<div class="source"><pre><span></span>    <span class="n">pretrained</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="n">GLOVE</span><span class="p">):</span>
        <span class="n">parts</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
        <span class="n">word</span> <span class="o">=</span> <span class="n">parts</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">vector</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">parts</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>
        <span class="n">pretrained</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">vector</span>
</pre></div>
</code>
</div>
<div class="outer  shared-content">
<div class="description shared-content">We need the word vectors as a list to initialise the embeddings. Each entry in the list corresponds to the token with that index.<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>    <span class="n">pretrained_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">3.0</span> <span class="o">/</span> <span class="n">DIM_EMBEDDING</span><span class="p">)</span> 
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">id_to_token</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="n">pretrained</span><span class="p">:</span> 
            <span class="n">pretrained_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pretrained</span><span class="p">[</span><span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">()]))</span>
        <span class="k">else</span><span class="p">:</span>
</pre></div>
</code>
<code class="pytorch">
<div class="source"><pre><span></span>    <span class="n">pretrained_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">3.0</span> <span class="o">/</span> <span class="n">DIM_EMBEDDING</span><span class="p">)</span> 
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">id_to_token</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="n">pretrained</span><span class="p">:</span> 
            <span class="n">pretrained_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pretrained</span><span class="p">[</span><span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">()]))</span>
        <span class="k">else</span><span class="p">:</span>
</pre></div>
</code>
<code class="dynet">
<div class="source"><pre><span></span>    <span class="n">pretrained_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">scale</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">3.0</span> <span class="o">/</span> <span class="n">DIM_EMBEDDING</span><span class="p">)</span> 
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">id_to_token</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="n">pretrained</span><span class="p">:</span> 
            <span class="n">pretrained_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pretrained</span><span class="p">[</span><span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">()]))</span>
        <span class="k">else</span><span class="p">:</span>
</pre></div>
</code>
</div>
<div class="outer  shared-content">
<div class="description shared-content">For words that do not appear in GloVe we generate a random vector (note, the choice of scale here is important).<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>            <span class="n">random_vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">scale</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="p">[</span><span class="n">DIM_EMBEDDING</span><span class="p">])</span>
            <span class="n">pretrained_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">random_vector</span><span class="p">)</span>

</pre></div></code>
<code class="pytorch">
<div class="source"><pre><span></span>            <span class="n">random_vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">scale</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="p">[</span><span class="n">DIM_EMBEDDING</span><span class="p">])</span>
            <span class="n">pretrained_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">random_vector</span><span class="p">)</span>

</pre></div></code>
<code class="dynet">
<div class="source"><pre><span></span>            <span class="n">random_vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">scale</span><span class="p">,</span> <span class="n">scale</span><span class="p">,</span> <span class="p">[</span><span class="n">DIM_EMBEDDING</span><span class="p">])</span>
            <span class="n">pretrained_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">random_vector</span><span class="p">)</span>

</pre></div></code>
</div>
<div class="outer  dynet">
<div class="description dynet"><br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
&nbsp;</code>
<code class="dynet">
<div class="source"><pre><span></span>    <span class="c1"># DyNet model creation</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">dy</span><span class="o">.</span><span class="n">ParameterCollection</span><span class="p">()</span>
</pre></div>
</code>
</div>
<div class="outer  dynet">
<div class="description dynet">Lookup parameters are a matrix that supports efficient sparse lookup.<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
&nbsp;</code>
<code class="dynet">
<div class="source"><pre><span></span>    <span class="n">pEmbedding</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">add_lookup_parameters</span><span class="p">((</span><span class="n">NWORDS</span><span class="p">,</span> <span class="n">DIM_EMBEDDING</span><span class="p">))</span>
    <span class="n">pEmbedding</span><span class="o">.</span><span class="n">init_from_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pretrained_list</span><span class="p">))</span>
</pre></div>
</code>
</div>
<div class="outer  dynet">
<div class="description dynet">Objects that create LSTM cells and the necessary parameters.<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
&nbsp;</code>
<code class="dynet">
<div class="source"><pre><span></span>    <span class="n">stdv</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">LSTM_HIDDEN</span><span class="p">)</span> 
    <span class="n">f_lstm</span> <span class="o">=</span> <span class="n">dy</span><span class="o">.</span><span class="n">VanillaLSTMBuilder</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">DIM_EMBEDDING</span><span class="p">,</span> <span class="n">LSTM_HIDDEN</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span>
            <span class="n">forget_bias</span><span class="o">=</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random_sample</span><span class="p">()</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">stdv</span><span class="p">)</span>
    <span class="n">b_lstm</span> <span class="o">=</span> <span class="n">dy</span><span class="o">.</span><span class="n">VanillaLSTMBuilder</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">DIM_EMBEDDING</span><span class="p">,</span> <span class="n">LSTM_HIDDEN</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span>
            <span class="n">forget_bias</span><span class="o">=</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random_sample</span><span class="p">()</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">stdv</span><span class="p">)</span>
</pre></div>
</code>
</div>
<div class="outer  dynet">
<div class="description dynet">A simple weight matrix for the final output calculation.<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
&nbsp;</code>
<code class="dynet">
<div class="source"><pre><span></span>    <span class="n">pOutput</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">add_parameters</span><span class="p">((</span><span class="n">NTAGS</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">LSTM_HIDDEN</span><span class="p">))</span>

</pre></div></code>
</div>
<div class="outer  dynet">
<div class="description dynet">Setting recurrent dropout values (not used in this case).<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
&nbsp;</code>
<code class="dynet">
<div class="source"><pre><span></span>    <span class="n">f_lstm</span><span class="o">.</span><span class="n">set_dropouts</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
    <span class="n">b_lstm</span><span class="o">.</span><span class="n">set_dropouts</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
</pre></div>
</code>
</div>
<div class="outer  dynet">
<div class="description dynet">To match PyTorch, we initialise the parameters with an unconventional approach.<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
&nbsp;</code>
<code class="dynet">
<div class="source"><pre><span></span>    <span class="n">f_lstm</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">stdv</span><span class="p">,</span> <span class="n">stdv</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span> <span class="o">*</span> <span class="n">LSTM_HIDDEN</span><span class="p">,</span> <span class="n">DIM_EMBEDDING</span><span class="p">]))</span>
    <span class="n">f_lstm</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">stdv</span><span class="p">,</span> <span class="n">stdv</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span> <span class="o">*</span> <span class="n">LSTM_HIDDEN</span><span class="p">,</span> <span class="n">LSTM_HIDDEN</span><span class="p">]))</span>
    <span class="n">f_lstm</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">stdv</span><span class="p">,</span> <span class="n">stdv</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span> <span class="o">*</span> <span class="n">LSTM_HIDDEN</span><span class="p">]))</span>
    <span class="n">b_lstm</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">stdv</span><span class="p">,</span> <span class="n">stdv</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span> <span class="o">*</span> <span class="n">LSTM_HIDDEN</span><span class="p">,</span> <span class="n">DIM_EMBEDDING</span><span class="p">]))</span>
    <span class="n">b_lstm</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">stdv</span><span class="p">,</span> <span class="n">stdv</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span> <span class="o">*</span> <span class="n">LSTM_HIDDEN</span><span class="p">,</span> <span class="n">LSTM_HIDDEN</span><span class="p">]))</span>
    <span class="n">b_lstm</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">stdv</span><span class="p">,</span> <span class="n">stdv</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span> <span class="o">*</span> <span class="n">LSTM_HIDDEN</span><span class="p">]))</span>

</pre></div></code>
</div>
<div class="outer  dynet">
<div class="description dynet">The trainer object is used to update the model.
<br />
DyNet clips gradients by default, which we disable here (this can have a big impact on performance).<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
&nbsp;</code>
<code class="dynet">
<div class="source"><pre><span></span>    <span class="n">trainer</span> <span class="o">=</span> <span class="n">dy</span><span class="o">.</span><span class="n">SimpleSGDTrainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">LEARNING_RATE</span><span class="p">)</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">set_clip_threshold</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

</pre></div></code>
</div>
<div class="outer  pytorch">
<div class="description pytorch"><br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>    <span class="c1"># PyTorch model creation</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">TaggerModel</span><span class="p">(</span><span class="n">NWORDS</span><span class="p">,</span> <span class="n">NTAGS</span><span class="p">,</span> <span class="n">pretrained_list</span><span class="p">,</span> <span class="n">id_to_token</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LEARNING_RATE</span><span class="p">,</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="n">WEIGHT_DECAY</span><span class="p">)</span>
</pre></div>
</code>
<code class="dynet">
&nbsp;</code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">The learning rate for each epoch is set by multiplying the inital rate by the factor produced by this function.<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>    <span class="n">rescale_lr</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">epoch</span><span class="p">:</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">LEARNING_DECAY_RATE</span> <span class="o">*</span> <span class="n">epoch</span><span class="p">)</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">LambdaLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span>
            <span class="n">lr_lambda</span><span class="o">=</span><span class="n">rescale_lr</span><span class="p">)</span>

</pre></div></code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow"><br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>    <span class="c1"># Tensorflow computation graph definition</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
</pre></div>
</code>
<code class="pytorch">
&nbsp;</code>
<code class="dynet">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">Placeholders are inputs/values that will be fed into the network each time it is run. We define their type and the shape (constant, 1D vector, 2D vector, etc). This includes what we normally think of as inputs (e.g. the tokens) as well as parameters we want to change at run time (e.g. the learning rate).<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="n">e_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;input&#39;</span><span class="p">)</span>
        <span class="n">e_lengths</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;lengths&#39;</span><span class="p">)</span>
        <span class="n">e_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;mask&#39;</span><span class="p">)</span>
        <span class="n">e_gold_output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">],</span>
                <span class="n">name</span><span class="o">=</span><span class="s1">&#39;gold_output&#39;</span><span class="p">)</span>
        <span class="n">e_keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;keep_prob&#39;</span><span class="p">)</span>
        <span class="n">e_learning_rate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">)</span>

</pre></div></code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">The embedding matrix is a variable (so they can shift in training), initialized with the vectors defined above.<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="n">glove_init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant_initializer</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pretrained_list</span><span class="p">))</span>
        <span class="n">e_embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s2">&quot;embedding&quot;</span><span class="p">,</span> <span class="p">[</span><span class="n">NWORDS</span><span class="p">,</span> <span class="n">DIM_EMBEDDING</span><span class="p">],</span>
                <span class="n">initializer</span><span class="o">=</span><span class="n">glove_init</span><span class="p">)</span>
        <span class="n">e_embed</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">e_embedding</span><span class="p">,</span> <span class="n">e_input</span><span class="p">)</span>

</pre></div></code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">We create an LSTM cell, then wrap it in a class that applies dropout.<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="n">e_cell_f</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="n">LSTM_HIDDEN</span><span class="p">)</span>
        <span class="n">e_cell_f</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">e_cell_f</span><span class="p">,</span>
                <span class="n">input_keep_prob</span><span class="o">=</span><span class="n">e_keep_prob</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">e_keep_prob</span><span class="p">)</span>
</pre></div>
</code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">Recurrent dropout options<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="c1">#        variational_recurrent=True, dtype=tf.float32,</span>
        <span class="c1">#        input_size=DIM_EMBEDDING)</span>
</pre></div>
</code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">For a multi-layer network we would wrap a list of cells with MultiRNNCell<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="c1"># e_cell_f = tf.contrib.rnn.MultiRNNCell([e_cell_f])</span>
</pre></div>
</code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">Make a cell for the reverse direction<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="n">e_cell_b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="n">LSTM_HIDDEN</span><span class="p">)</span>
        <span class="n">e_cell_b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">e_cell_b</span><span class="p">,</span>
                <span class="n">input_keep_prob</span><span class="o">=</span><span class="n">e_keep_prob</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">e_keep_prob</span><span class="p">)</span>

</pre></div></code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">To use the cells we create a dynamic RNN. The 'dynamic' aspect means we can feed in the lengths of input sequences not counting padding and it will stop early.<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="n">e_initial_state_f</span> <span class="o">=</span> <span class="n">e_cell_f</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">e_initial_state_b</span> <span class="o">=</span> <span class="n">e_cell_f</span><span class="o">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">e_lstm_outputs</span><span class="p">,</span> <span class="n">e_final_state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">bidirectional_dynamic_rnn</span><span class="p">(</span>
                <span class="n">cell_fw</span><span class="o">=</span><span class="n">e_cell_f</span><span class="p">,</span> <span class="n">cell_bw</span><span class="o">=</span><span class="n">e_cell_b</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">e_embed</span><span class="p">,</span>
                <span class="n">initial_state_fw</span><span class="o">=</span><span class="n">e_initial_state_f</span><span class="p">,</span>
                <span class="n">initial_state_bw</span><span class="o">=</span><span class="n">e_initial_state_b</span><span class="p">,</span>
                <span class="n">sequence_length</span><span class="o">=</span><span class="n">e_lengths</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">e_lstm_outputs_merged</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">e_lstm_outputs</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

</pre></div></code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">Matrix multiply to get scores for each class<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="n">e_predictions</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span><span class="n">e_lstm_outputs_merged</span><span class="p">,</span>
                <span class="n">NTAGS</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</pre></div>
</code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">Cross-entropy loss. The reduction flag is crucial (the default is to average over the sequence). The weights flag accounts for padding that makes all of the sequences the same length.<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="n">e_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">sparse_softmax_cross_entropy</span><span class="p">(</span><span class="n">e_gold_output</span><span class="p">,</span>
                <span class="n">e_predictions</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">e_mask</span><span class="p">,</span>
                <span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reduction</span><span class="o">.</span><span class="n">SUM</span><span class="p">)</span>
</pre></div>
</code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">Update computation - one step option<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="n">e_train</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">e_learning_rate</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">e_loss</span><span class="p">)</span>
</pre></div>
</code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">Update computation - multi-step, so that (for example) gradient clipping can be applied<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="c1"># e_optimiser = tf.train.GradientDescentOptimizer(LEARNING_RATE)</span>
        <span class="c1"># e_gradients = e_optimiser.compute_gradients(e_loss)</span>
        <span class="c1"># e_clipped_gradients = [(tf.clip_by_value(grad, -5., 5.), var)</span>
        <span class="c1">#         for grad, var in e_gradients]</span>
        <span class="c1"># e_train = e_optimiser.apply_gradients(e_gradients)</span>

</pre></div></code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">Get the predicted label<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="n">e_auto_output</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">e_predictions</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

</pre></div></code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">Use computation graph<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
</pre></div>
</code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">Configure the system environment. By default tensorflow uses all available GPUs and RAM. These lines limit the number of GPUs used and the amount of RAM. To limit which GPUs are used, set the environment variable CUDA_VISIBLE_DEVICES (e.g. "export CUDA_VISIBLE_DEVICES=0,1").<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="n">config</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ConfigProto</span><span class="p">(</span>
            <span class="n">device_count</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;GPU&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">},</span>
            <span class="n">gpu_options</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">GPUOptions</span><span class="p">(</span><span class="n">per_process_gpu_memory_fraction</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
</pre></div>
</code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">Initialise all variables<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

</pre></div></code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  shared-content">
<div class="description shared-content">Main training loop, in which we shuffle the data, set the learning rate, do one complete pass over the training data, then evaluate on the development data.
<br />
To make the code match across the three versions, we group together some framework specifc values needed when doing a pass over the data.<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>            <span class="n">expressions</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">e_auto_output</span><span class="p">,</span> <span class="n">e_gold_output</span><span class="p">,</span> <span class="n">e_input</span><span class="p">,</span> <span class="n">e_keep_prob</span><span class="p">,</span> <span class="n">e_lengths</span><span class="p">,</span>
                <span class="n">e_loss</span><span class="p">,</span> <span class="n">e_train</span><span class="p">,</span> <span class="n">e_mask</span><span class="p">,</span> <span class="n">e_learning_rate</span><span class="p">,</span> <span class="n">sess</span>
            <span class="p">]</span>
            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
                <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>

</pre></div></code>
<code class="pytorch">
<div class="source"><pre><span></span>    <span class="n">expressions</span> <span class="o">=</span> <span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
        <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>

</pre></div></code>
<code class="dynet">
<div class="source"><pre><span></span>    <span class="n">expressions</span> <span class="o">=</span> <span class="p">(</span><span class="n">pEmbedding</span><span class="p">,</span> <span class="n">pOutput</span><span class="p">,</span> <span class="n">f_lstm</span><span class="p">,</span> <span class="n">b_lstm</span><span class="p">,</span> <span class="n">trainer</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
        <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>

</pre></div></code>
</div>
<div class="outer  shared-content">
<div class="description shared-content">Determine the current learning rate<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>                <span class="n">current_lr</span> <span class="o">=</span> <span class="n">LEARNING_RATE</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span> <span class="n">LEARNING_DECAY_RATE</span> <span class="o">*</span> <span class="n">epoch</span><span class="p">)</span>

</pre></div></code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

</pre></div></code>
<code class="dynet">
<div class="source"><pre><span></span>        <span class="n">trainer</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">LEARNING_RATE</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span> <span class="n">LEARNING_DECAY_RATE</span> <span class="o">*</span> <span class="n">epoch</span><span class="p">)</span>

</pre></div></code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">Set in training mode, which does things like enable dropout components, and initialise the gradient to zero.<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span> 
        <span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</pre></div>
</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  shared-content">
<div class="description shared-content">Training pass<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>                <span class="n">loss</span><span class="p">,</span> <span class="n">tacc</span> <span class="o">=</span> <span class="n">do_pass</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">token_to_id</span><span class="p">,</span> <span class="n">tag_to_id</span><span class="p">,</span>
                        <span class="n">expressions</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span> <span class="n">current_lr</span><span class="p">)</span>
</pre></div>
</code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="n">loss</span><span class="p">,</span> <span class="n">tacc</span> <span class="o">=</span> <span class="n">do_pass</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">token_to_id</span><span class="p">,</span> <span class="n">tag_to_id</span><span class="p">,</span> <span class="n">expressions</span><span class="p">,</span>
                <span class="bp">True</span><span class="p">)</span>

</pre></div></code>
<code class="dynet">
<div class="source"><pre><span></span>        <span class="n">loss</span><span class="p">,</span> <span class="n">tacc</span> <span class="o">=</span> <span class="n">do_pass</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">token_to_id</span><span class="p">,</span> <span class="n">tag_to_id</span><span class="p">,</span> <span class="n">expressions</span><span class="p">,</span> <span class="bp">True</span><span class="p">,</span>
                <span class="n">current_lr</span><span class="p">)</span>
</pre></div>
</code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">Set in evaluation mode, which does things like disable dropout components<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  shared-content">
<div class="description shared-content">Dev pass<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>                <span class="n">_</span><span class="p">,</span> <span class="n">dacc</span> <span class="o">=</span> <span class="n">do_pass</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">token_to_id</span><span class="p">,</span> <span class="n">tag_to_id</span><span class="p">,</span> <span class="n">expressions</span><span class="p">,</span>
                        <span class="bp">False</span><span class="p">)</span>
                <span class="k">print</span><span class="p">(</span><span class="s2">&quot;{} loss {} t-acc {} d-acc {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">tacc</span><span class="p">,</span>
                    <span class="n">dacc</span><span class="p">))</span>

</pre></div></code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="n">_</span><span class="p">,</span> <span class="n">dacc</span> <span class="o">=</span> <span class="n">do_pass</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">token_to_id</span><span class="p">,</span> <span class="n">tag_to_id</span><span class="p">,</span> <span class="n">expressions</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;{} loss {} t-acc {} d-acc {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span>
            <span class="n">tacc</span><span class="p">,</span> <span class="n">dacc</span><span class="p">))</span>

</pre></div></code>
<code class="dynet">
<div class="source"><pre><span></span>        <span class="n">_</span><span class="p">,</span> <span class="n">dacc</span> <span class="o">=</span> <span class="n">do_pass</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">token_to_id</span><span class="p">,</span> <span class="n">tag_to_id</span><span class="p">,</span> <span class="n">expressions</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;{} loss {} t-acc {} d-acc {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">tacc</span><span class="p">,</span> <span class="n">dacc</span><span class="p">))</span>

</pre></div></code>
</div>
<div class="outer  shared-content">
<div class="description shared-content">Save and load model. Both must be done after the definitions above (ie, the model should be recreated, then have its parameters set to match this saved version).<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>            <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s2">&quot;./tagger.tf.model&quot;</span><span class="p">)</span>
            <span class="n">saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s2">&quot;./tagger.tf.model&quot;</span><span class="p">)</span>

</pre></div></code>
<code class="pytorch">
<div class="source"><pre><span></span>    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s2">&quot;tagger.pt.model&quot;</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;tagger.pt.model&#39;</span><span class="p">))</span>

</pre></div></code>
<code class="dynet">
<div class="source"><pre><span></span>    <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;tagger.dy.model&quot;</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">populate</span><span class="p">(</span><span class="s2">&quot;tagger.dy.model&quot;</span><span class="p">)</span>

</pre></div></code>
</div>
<div class="outer  shared-content">
<div class="description shared-content">Evaluation<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>            <span class="n">_</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">do_pass</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">token_to_id</span><span class="p">,</span> <span class="n">tag_to_id</span><span class="p">,</span> <span class="n">expressions</span><span class="p">,</span>
                    <span class="bp">False</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Test Accuracy: {:.3f}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_acc</span><span class="p">))</span>

</pre></div></code>
<code class="pytorch">
<div class="source"><pre><span></span>    <span class="n">_</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">do_pass</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">token_to_id</span><span class="p">,</span> <span class="n">tag_to_id</span><span class="p">,</span> <span class="n">expressions</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Test Accuracy: {:.3f}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_acc</span><span class="p">))</span>

</pre></div></code>
<code class="dynet">
<div class="source"><pre><span></span>    <span class="n">_</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">do_pass</span><span class="p">(</span><span class="n">dev</span><span class="p">,</span> <span class="n">token_to_id</span><span class="p">,</span> <span class="n">tag_to_id</span><span class="p">,</span> <span class="n">expressions</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Test Accuracy: {:.3f}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_acc</span><span class="p">))</span>

</pre></div></code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">Neural network definition code. In PyTorch networks are defined using classes that extend Module.<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span><span class="k">class</span> <span class="nc">TaggerModel</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</pre></div>
</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">In the constructor we define objects that will do each of the computations<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nwords</span><span class="p">,</span> <span class="n">ntags</span><span class="p">,</span> <span class="n">pretrained_list</span><span class="p">,</span> <span class="n">id_to_token</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

</pre></div></code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">Convert the word embeddings into a PyTorch tensor<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="n">pretrained_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">pretrained_list</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">word_embedding</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
                <span class="n">pretrained_tensor</span><span class="p">,</span> <span class="n">freeze</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">word_dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">KEEP_PROB</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">DIM_EMBEDDING</span><span class="p">,</span> <span class="n">LSTM_HIDDEN</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm_output_dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">KEEP_PROB</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_to_tag</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">LSTM_HIDDEN</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">ntags</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentences</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="n">cur_batch_size</span><span class="p">):</span>
        <span class="n">max_length</span> <span class="o">=</span> <span class="n">sentences</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

</pre></div></code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">Look up word vectors<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="n">word_vectors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_embedding</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
</pre></div>
</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">Apply dropout<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="n">dropped_word_vectors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">word_dropout</span><span class="p">(</span><span class="n">word_vectors</span><span class="p">)</span>

</pre></div></code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">Assuming the data is ordered longest to shortest, this provides a view of the data that fits with how cuDNN works<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="n">packed_words</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pack_padded_sequence</span><span class="p">(</span>
                <span class="n">dropped_word_vectors</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
</pre></div>
</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">Run the LSTM over the input<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="n">lstm_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">packed_words</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
</pre></div>
</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">Reverse the view shift made for cuDNN. Specifying total_length is not necessary in general (it can be inferred), but is necessary for parallel processing.<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="n">lstm_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">pad_packed_sequence</span><span class="p">(</span><span class="n">lstm_out</span><span class="p">,</span>
                <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">total_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">)</span>
</pre></div>
</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">Apply dropout to the output<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="n">lstm_out_dropped</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm_output_dropout</span><span class="p">(</span><span class="n">lstm_out</span><span class="p">)</span>
</pre></div>
</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">Matrix multiply to get distribution over tags<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="n">output_scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_to_tag</span><span class="p">(</span><span class="n">lstm_out_dropped</span><span class="p">)</span>

</pre></div></code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">Reshape to [batch size * sequence length, ntags] for more efficient processing<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="n">output_scores</span> <span class="o">=</span> <span class="n">output_scores</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">cur_batch_size</span> <span class="o">*</span> <span class="n">max_length</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">flat_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">cur_batch_size</span> <span class="o">*</span> <span class="n">max_length</span><span class="p">)</span>
</pre></div>
</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">Calculate the cross entropy loss, ignoring padding, and summing losses across the batch<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">ignore_index</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">output_scores</span><span class="p">,</span> <span class="n">flat_labels</span><span class="p">)</span>
</pre></div>
</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">Identify the highest scoring tag in each case and reshape to be [batch, sequence]<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="n">_</span><span class="p">,</span> <span class="n">predicted_tags</span>  <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">output_scores</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">predicted_tags</span> <span class="o">=</span> <span class="n">predicted_tags</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">cur_batch_size</span><span class="p">,</span> <span class="n">max_length</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">predicted_tags</span>

</pre></div></code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  shared-content">
<div class="description shared-content">Inference (the same function for train and test)<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span><span class="k">def</span> <span class="nf">do_pass</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">token_to_id</span><span class="p">,</span> <span class="n">tag_to_id</span><span class="p">,</span> <span class="n">expressions</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
    <span class="n">e_auto_output</span><span class="p">,</span> <span class="n">e_gold_output</span><span class="p">,</span> <span class="n">e_input</span><span class="p">,</span> <span class="n">e_keep_prob</span><span class="p">,</span> <span class="n">e_lengths</span><span class="p">,</span> <span class="n">e_loss</span><span class="p">,</span> \
            <span class="n">e_train</span><span class="p">,</span> <span class="n">e_mask</span><span class="p">,</span> <span class="n">e_learning_rate</span><span class="p">,</span> <span class="n">session</span> <span class="o">=</span> <span class="n">expressions</span>

</pre></div></code>
<code class="pytorch">
<div class="source"><pre><span></span><span class="k">def</span> <span class="nf">do_pass</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">token_to_id</span><span class="p">,</span> <span class="n">tag_to_id</span><span class="p">,</span> <span class="n">expressions</span><span class="p">,</span> <span class="n">train</span><span class="p">):</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="n">expressions</span>

</pre></div></code>
<code class="dynet">
<div class="source"><pre><span></span><span class="k">def</span> <span class="nf">do_pass</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">token_to_id</span><span class="p">,</span> <span class="n">tag_to_id</span><span class="p">,</span> <span class="n">expressions</span><span class="p">,</span> <span class="n">train</span><span class="p">):</span>
    <span class="n">pEmbedding</span><span class="p">,</span> <span class="n">pOutput</span><span class="p">,</span> <span class="n">f_lstm</span><span class="p">,</span> <span class="n">b_lstm</span><span class="p">,</span> <span class="n">trainer</span> <span class="o">=</span> <span class="n">expressions</span>

</pre></div></code>
</div>
<div class="outer  shared-content">
<div class="description shared-content">Loop over batches, tracking the start of the batch in the data<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">match</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="n">start</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
</pre></div>
</code>
<code class="pytorch">
<div class="source"><pre><span></span>    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">match</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="n">start</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
</pre></div>
</code>
<code class="dynet">
<div class="source"><pre><span></span>    <span class="n">loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">match</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">start</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="n">start</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
</pre></div>
</code>
</div>
<div class="outer  shared-content">
<div class="description shared-content">Form the batch and order it based on length (not necessary for DyNet, but important for efficient processing in PyTorch).<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="n">batch</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">start</span> <span class="p">:</span> <span class="n">start</span> <span class="o">+</span> <span class="n">BATCH_SIZE</span><span class="p">]</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">start</span> <span class="o">+=</span> <span class="n">BATCH_SIZE</span>
</pre></div>
</code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="n">batch</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">start</span> <span class="p">:</span> <span class="n">start</span> <span class="o">+</span> <span class="n">BATCH_SIZE</span><span class="p">]</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">start</span> <span class="o">+=</span> <span class="n">BATCH_SIZE</span>
</pre></div>
</code>
<code class="dynet">
<div class="source"><pre><span></span>        <span class="n">batch</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">start</span> <span class="p">:</span> <span class="n">start</span> <span class="o">+</span> <span class="n">BATCH_SIZE</span><span class="p">]</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">start</span> <span class="o">+=</span> <span class="n">BATCH_SIZE</span>
</pre></div>
</code>
</div>
<div class="outer  shared-content">
<div class="description shared-content">Log partial results so we can conveniently check progress<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="k">if</span> <span class="n">start</span> <span class="o">%</span> <span class="mi">4000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">match</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

</pre></div></code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="k">if</span> <span class="n">start</span> <span class="o">%</span> <span class="mi">4000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">match</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

</pre></div></code>
<code class="dynet">
<div class="source"><pre><span></span>        <span class="k">if</span> <span class="n">start</span> <span class="o">%</span> <span class="mi">4000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">print</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">match</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

</pre></div></code>
</div>
<div class="outer  dynet">
<div class="description dynet">Start a new computation graph for this batch<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
&nbsp;</code>
<code class="dynet">
<div class="source"><pre><span></span>        <span class="n">dy</span><span class="o">.</span><span class="n">renew_cg</span><span class="p">()</span>
</pre></div>
</code>
</div>
<div class="outer  dynet">
<div class="description dynet">For each example, we will construct an expression that gives the loss.<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
&nbsp;</code>
<code class="dynet">
<div class="source"><pre><span></span>        <span class="n">loss_expressions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">predicted</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">tags</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
</pre></div>
</code>
</div>
<div class="outer  dynet">
<div class="description dynet">Convert tokens and tags from strings to numbers using the indices<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
&nbsp;</code>
<code class="dynet">
<div class="source"><pre><span></span>            <span class="n">token_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">token_to_id</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">simplify_token</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
            <span class="n">tag_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">tag_to_id</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tags</span><span class="p">]</span>

</pre></div></code>
</div>
<div class="outer  dynet">
<div class="description dynet">Look up word embeddings<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
&nbsp;</code>
<code class="dynet">
<div class="source"><pre><span></span>            <span class="n">wembs</span> <span class="o">=</span> <span class="p">[</span><span class="n">dy</span><span class="o">.</span><span class="n">lookup</span><span class="p">(</span><span class="n">pEmbedding</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">token_ids</span><span class="p">]</span>
</pre></div>
</code>
</div>
<div class="outer  dynet">
<div class="description dynet">During training, apply dropout to the inputs<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
&nbsp;</code>
<code class="dynet">
<div class="source"><pre><span></span>            <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
                <span class="n">wembs</span> <span class="o">=</span> <span class="p">[</span><span class="n">dy</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">KEEP_PROB</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">wembs</span><span class="p">]</span>
</pre></div>
</code>
</div>
<div class="outer  dynet">
<div class="description dynet">Create an expression for two LSTMs and feed in the embeddings (reversed in one case).
<br />
We pull out the output vector from the cell state at each step.<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
&nbsp;</code>
<code class="dynet">
<div class="source"><pre><span></span>            <span class="n">f_init</span> <span class="o">=</span> <span class="n">f_lstm</span><span class="o">.</span><span class="n">initial_state</span><span class="p">()</span>
            <span class="n">f_lstm_output</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">output</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">f_init</span><span class="o">.</span><span class="n">add_inputs</span><span class="p">(</span><span class="n">wembs</span><span class="p">)]</span>
            <span class="n">rev_embs</span> <span class="o">=</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">wembs</span><span class="p">)</span>
            <span class="n">b_init</span> <span class="o">=</span> <span class="n">b_lstm</span><span class="o">.</span><span class="n">initial_state</span><span class="p">()</span>
            <span class="n">b_lstm_output</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">output</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">b_init</span><span class="o">.</span><span class="n">add_inputs</span><span class="p">(</span><span class="n">rev_embs</span><span class="p">)]</span>

            <span class="n">pred_tags</span> <span class="o">=</span> <span class="p">[]</span>
</pre></div>
</code>
</div>
<div class="outer  dynet">
<div class="description dynet">Combine the outputs<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
&nbsp;</code>
<code class="dynet">
<div class="source"><pre><span></span>            <span class="k">for</span> <span class="n">f</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">f_lstm_output</span><span class="p">,</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">b_lstm_output</span><span class="p">),</span> <span class="n">tag_ids</span><span class="p">):</span>
                <span class="n">combined</span> <span class="o">=</span> <span class="n">dy</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">f</span><span class="p">,</span><span class="n">b</span><span class="p">])</span>
</pre></div>
</code>
</div>
<div class="outer  dynet">
<div class="description dynet">Apply dropout to the output<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
&nbsp;</code>
<code class="dynet">
<div class="source"><pre><span></span>                <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
                    <span class="n">combined</span> <span class="o">=</span> <span class="n">dy</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">combined</span><span class="p">,</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">KEEP_PROB</span><span class="p">)</span>
</pre></div>
</code>
</div>
<div class="outer  dynet">
<div class="description dynet">Multiple by a matrix to get scores for each tag<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
&nbsp;</code>
<code class="dynet">
<div class="source"><pre><span></span>                <span class="n">r_t</span> <span class="o">=</span> <span class="n">pOutput</span> <span class="o">*</span> <span class="n">combined</span>
                <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
</pre></div>
</code>
</div>
<div class="outer  dynet">
<div class="description dynet">When training, get an expression for the cross-entropy loss<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
&nbsp;</code>
<code class="dynet">
<div class="source"><pre><span></span>                    <span class="n">err</span> <span class="o">=</span> <span class="n">dy</span><span class="o">.</span><span class="n">pickneglogsoftmax</span><span class="p">(</span><span class="n">r_t</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
                    <span class="n">loss_expressions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">err</span><span class="p">)</span>
</pre></div>
</code>
</div>
<div class="outer  dynet">
<div class="description dynet">Calculate the highest scoring tag (which will lead to evaluation of the graph)<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
&nbsp;</code>
<code class="dynet">
<div class="source"><pre><span></span>                <span class="n">chosen</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">r_t</span><span class="o">.</span><span class="n">npvalue</span><span class="p">())</span>
                <span class="n">pred_tags</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chosen</span><span class="p">)</span>
            <span class="n">predicted</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred_tags</span><span class="p">)</span>

</pre></div></code>
</div>
<div class="outer  dynet">
<div class="description dynet">During training, combine the losses for the batch, do an update, and record the loss<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
&nbsp;</code>
<code class="dynet">
<div class="source"><pre><span></span>        <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
            <span class="n">loss_for_batch</span> <span class="o">=</span> <span class="n">dy</span><span class="o">.</span><span class="n">esum</span><span class="p">(</span><span class="n">loss_expressions</span><span class="p">)</span>
            <span class="n">loss_for_batch</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">loss_for_batch</span><span class="o">.</span><span class="n">scalar_value</span><span class="p">()</span>

</pre></div></code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">Prepare input arrays, using .long() to cast the type from Tensor to LongTensor.<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="n">cur_batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">max_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">]</span>
        <span class="n">input_array</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">cur_batch_size</span><span class="p">,</span> <span class="n">max_length</span><span class="p">))</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="n">output_array</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">cur_batch_size</span><span class="p">,</span> <span class="n">max_length</span><span class="p">))</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">tags</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
</pre></div>
</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">Using the indices we map our srings to numbers.<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>            <span class="n">token_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">token_to_id</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">simplify_token</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
            <span class="n">tag_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">tag_to_id</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tags</span><span class="p">]</span>
</pre></div>
</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">Fill the arrays, leaving the remaining values as zero (our padding value).<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>            <span class="n">input_array</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span>
            <span class="n">output_array</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">tags</span><span class="p">)]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">(</span><span class="n">tag_ids</span><span class="p">)</span>

</pre></div></code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">Calling the model as a function will run its forward() function, which constructs the network.<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="n">batch_loss</span><span class="p">,</span> <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_array</span><span class="p">,</span> <span class="n">output_array</span><span class="p">,</span> <span class="n">lengths</span><span class="p">,</span>
                <span class="n">cur_batch_size</span><span class="p">)</span>

</pre></div></code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">In training we do the backwards pass, apply the update, and reset the gradient.<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
            <span class="n">batch_loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">model</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</pre></div>
</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">To get the loss value we use .item().<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>            <span class="n">loss</span> <span class="o">+=</span> <span class="n">batch_loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</pre></div>
</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  pytorch">
<div class="description pytorch">Our output is an array (rather than a single value), so we use a different approach to get it into a usable form.<br /><br /></div>
<code class="tensorflow">
&nbsp;</code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="n">predicted</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

</pre></div></code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">Add empty sentences to fill in batch<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="n">batch</span> <span class="o">+=</span> <span class="p">[([],</span> <span class="p">[])</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">BATCH_SIZE</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">))]</span>
</pre></div>
</code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">Prepare input. We do this here for convenience and to have greater alignment between code above, but in practise it would be best to do this once in pre-processing.<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="n">max_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">input_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="n">max_length</span><span class="p">])</span>
        <span class="n">output_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="n">max_length</span><span class="p">])</span>
        <span class="n">lengths</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">])</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">),</span> <span class="n">max_length</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="n">tags</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
</pre></div>
</code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">Using the indices we map our srings to numbers<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>            <span class="n">token_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">token_to_id</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">simplify_token</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
            <span class="n">tag_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">tag_to_id</span><span class="p">[</span><span class="n">t</span><span class="p">]</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tags</span><span class="p">]</span>
</pre></div>
</code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">Fill the arrays, leaving the remaining values as zero (our padding value).<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>            <span class="n">input_array</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)]</span> <span class="o">=</span> <span class="n">token_ids</span>
            <span class="n">output_array</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">tags</span><span class="p">)]</span> <span class="o">=</span> <span class="n">tag_ids</span>
            <span class="n">mask</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)])</span>
</pre></div>
</code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">We can't change the computation graph to disable dropout when not training, so we just change the keep probability.<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="n">cur_keep_prob</span> <span class="o">=</span> <span class="n">KEEP_PROB</span> <span class="k">if</span> <span class="n">train</span> <span class="k">else</span> <span class="mf">1.0</span>

</pre></div></code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">This dictionary contains values for all of the placeholders we defined.<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="n">feed</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">e_input</span><span class="p">:</span> <span class="n">input_array</span><span class="p">,</span>
                <span class="n">e_gold_output</span><span class="p">:</span> <span class="n">output_array</span><span class="p">,</span>
                <span class="n">e_mask</span><span class="p">:</span> <span class="n">mask</span><span class="p">,</span>
                <span class="n">e_keep_prob</span><span class="p">:</span> <span class="n">cur_keep_prob</span><span class="p">,</span>
                <span class="n">e_lengths</span><span class="p">:</span> <span class="n">lengths</span><span class="p">,</span>
                <span class="n">e_learning_rate</span><span class="p">:</span> <span class="n">lr</span>
        <span class="p">}</span>
</pre></div>
</code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">Define the computations we want tensorflow to complete. If we are not training we do not need to compute a loss and we do not want to do the update.<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="n">todo</span> <span class="o">=</span> <span class="p">[</span><span class="n">e_auto_output</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
            <span class="n">todo</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e_loss</span><span class="p">)</span>
            <span class="n">todo</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">e_train</span><span class="p">)</span>
</pre></div>
</code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">Running the network<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="n">outcomes</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">todo</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="n">feed</span><span class="p">)</span>
</pre></div>
</code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  tensorflow">
<div class="description tensorflow">Getting our values out. Note, we do not request the e_train value because its work is done - it performed the update during its computation.<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="n">predicted</span> <span class="o">=</span> <span class="n">outcomes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">+=</span> <span class="n">outcomes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

</pre></div></code>
<code class="pytorch empty">
&nbsp;</code>
<code class="dynet empty">
&nbsp;</code>
</div>
<div class="outer  shared-content">
<div class="description shared-content">Update the number of correct tags and total tags<br /><br /></div>
<code class="tensorflow">
<div class="source"><pre><span></span>        <span class="k">for</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">g</span><span class="p">),</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">predicted</span><span class="p">):</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">gt</span><span class="p">,</span> <span class="n">at</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span>
                <span class="n">gt</span> <span class="o">=</span> <span class="n">tag_to_id</span><span class="p">[</span><span class="n">gt</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">gt</span> <span class="o">==</span> <span class="n">at</span><span class="p">:</span>
                    <span class="n">match</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">match</span> <span class="o">/</span> <span class="n">total</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</code>
<code class="pytorch">
<div class="source"><pre><span></span>        <span class="k">for</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">g</span><span class="p">),</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">predicted</span><span class="p">):</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">gt</span><span class="p">,</span> <span class="n">at</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span>
                <span class="n">gt</span> <span class="o">=</span> <span class="n">tag_to_id</span><span class="p">[</span><span class="n">gt</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">gt</span> <span class="o">==</span> <span class="n">at</span><span class="p">:</span>
                    <span class="n">match</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">match</span> <span class="o">/</span> <span class="n">total</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</code>
<code class="dynet">
<div class="source"><pre><span></span>        <span class="k">for</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">g</span><span class="p">),</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">predicted</span><span class="p">):</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">gt</span><span class="p">,</span> <span class="n">at</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">a</span><span class="p">):</span>
                <span class="n">gt</span> <span class="o">=</span> <span class="n">tag_to_id</span><span class="p">[</span><span class="n">gt</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">gt</span> <span class="o">==</span> <span class="n">at</span><span class="p">:</span>
                    <span class="n">match</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">match</span> <span class="o">/</span> <span class="n">total</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</code>
</div>
<br /></div>


<script>
function toggleDyNet() {
    var dyitems = document.getElementsByClassName("dynet");
    var dybutton = document.getElementById("dybutton");
    for (var i = dyitems.length - 1; i >= 0; i--)
    {
        if (dyitems[i].style.display === "none") {
            dyitems[i].style.display = "block";
            dybutton.textContent = "Hide DyNet";
            dybutton.style.backgroundColor = "#008CBA";
        } else {
            dyitems[i].style.display = "none";
            dybutton.textContent = "Show DyNet";
            dybutton.style.backgroundColor = "#4CAF50";
        }
    }
    toggleShared();
}
function togglePyTorch() {
    var pyitems = document.getElementsByClassName("pytorch");
    var ptbutton = document.getElementById("ptbutton");
    for (var i = pyitems.length - 1; i >= 0; i--)
    {
        if (pyitems[i].style.display === "none") {
            pyitems[i].style.display = "block";
            ptbutton.textContent = "Hide PyTorch";
            ptbutton.style.backgroundColor = "#008CBA";
        } else {
            pyitems[i].style.display = "none";
            ptbutton.textContent = "Show PyTorch";
            ptbutton.style.backgroundColor = "#4CAF50";
        }
    }
    toggleShared();
}
function toggleTensorflow() {
    var tfitems = document.getElementsByClassName("tensorflow");
    var tfbutton = document.getElementById("tfbutton");
    for (var i = tfitems.length - 1; i >= 0; i--)
    {
        if (tfitems[i].style.display === "none") {
            tfitems[i].style.display = "block";
            tfbutton.textContent = "Hide Tensorflow";
            tfbutton.style.backgroundColor = "#008CBA";
        } else {
            tfitems[i].style.display = "none";
            tfbutton.textContent = "Show Tensorflow";
            tfbutton.style.backgroundColor = "#4CAF50";
        }
    }
    toggleShared();
}
function toggleShared() {
    var dybutton = document.getElementById("dybutton");
    var ptbutton = document.getElementById("ptbutton");
    var tfbutton = document.getElementById("tfbutton");
    var allitems = document.getElementsByClassName("shared-content");
    if (dybutton.textContent === "Show DyNet" && tfbutton.textContent === "Show Tensorflow" && ptbutton.textContent === "Show PyTorch") {
        for (var i = allitems.length - 1; i >= 0; i--)
        {
            allitems[i].style.display = "none";
        }
    } else {
        for (var i = allitems.length - 1; i >= 0; i--)
        {
            allitems[i].style.display = "block";
        }
    }
}
</script>

<div class="header-outer">
<div class="header">
<p>
A few miscellaneous notes:
<ul>
    <li>PyTorch 0.4 does not support recurrent dropout directly. For an example of how to achieve it, see the LSTM and QRNN Language Model Toolkit's <a href="https://github.com/salesforce/awd-lstm-lm/blob/28683b20154fce8e5812aeb6403e35010348c3ea/weight_drop.py">the WeightDrop class</a> and <a href="https://github.com/salesforce/awd-lstm-lm/blob/457a422eb46e970a6aad659ca815a04b3d074d6c/model.py#L22">how it is used</a>.</li>
    <li>Tensorflow 1.9 does not support weight decay directly, but <a href="https://github.com/tensorflow/tensorflow/pull/17438">this pull request</a> appears to add support and will be part of 1.10.</li>
</ul>
</p>
<p>
I developed this code with help from many people and resources. In particular:
<ul>
    <li> <a href="https://github.com/jiesutd/NCRFpp">NCRFpp</a>, the code associated with <a href="https://arxiv.org/abs/1806.04470">Yang, Liang, and Zhang (CoLing 2018)</a>, which was my starting point for PyTorch and my reference point when trying to check performance for the others.</li>
    <li> Members of the <a href="http://web.eecs.umich.edu/~wlasecki/croma.html">CROMA Lab</a> who gave feedback during development.</li>
    <li> Guillaume Genthial's blog post about <a href="https://guillaumegenthial.github.io/sequence-tagging-with-tensorflow.html">Sequence Tagging with Tensorflow</a>. </li>
    <li> The DyNet <a href="https://github.com/clab/dynet/blob/master/examples/tagger/bilstmtagger.py">example tagger</a>. </li>
</ul>
</p>
</div>
</div>

<div class="disqus">
<div id="disqus_thread"></div>
</div>
<script>
var disqus_config = function () {
    this.page.url = 'http://jkk.name/neural-tagger-tutorial/';
    this.page.identifier = '/neural-tagger-tutorial/';
    this.page.title = 'Neural Tagger Example';
};
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://www-jkk-name.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

</body>
</html>
