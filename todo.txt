


NCRFpp pretrained embedding handling:
 - use a GloVe vector if the word matches
 - if a word has no GloVe vector, but the lowercase form does, they use that
 - if that fails, a random vector is used

Why exactly 40k tokens? Doesn't match n>2 or all

Dropout:
- Applied equally to input and output
- NOT applied to recurrent

